Objective
The aim of this task is to explore, implement, and evaluate the K-Nearest Neighbors (KNN) classification algorithm on the Iris dataset to identify the optimal number of neighbors (K) and visualize decision boundaries for effective multi-class classification.

Tools Used
Pandas – For data manipulation
Matplotlib & Seaborn – For data visualization and plotting
Scikit-learn – For preprocessing, model building, and evaluation

Outputs
K Accuracy Plot: Line graph showing training and test accuracy for different values of K.
Best K Selection: Identified optimal K based on test accuracy.
Confusion Matrix & Classification Report: Evaluated performance using confusion matrix and precision/recall metrics.
Decision Boundary Plot: Visualized class separation using only two features.
Confusion Matrix Heatmap: Heatmap for easy visual comparison of actual vs. predicted classes
